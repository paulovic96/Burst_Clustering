{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paule/anaconda3/envs/bon17/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.nearest_centroid module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from spectral_clustering import spectral_clustering\n",
    "import functions_for_plotting\n",
    "from asymmetric_laplacian_distribution import get_index_per_class, get_labels, labels_to_layout_mapping\n",
    "from sklearn.cluster import KMeans\n",
    "import training_set_split\n",
    "import seaborn as sns\n",
    "import prediction_strength\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from prediction_strength import get_F1_score_per_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------- DATA ------------------------------------------------------------------\n",
    "data_dir = \"data/\"\n",
    "\n",
    "#clear_data = np.load(data_dir + \"clearly_separated_data_equal_noise=[0,1]_F_signal_noise.npy\")\n",
    "ambig_data = np.load(data_dir + \"ambiguous_data_equal_noise=[0,0.2]_F_signal_noise.npy\")\n",
    "#np.load(data_dir + \"ambiguous_data_tau_amplitude_F_signal_noise.npy\") #np.load(data_dir + \"clearly_separated_data_F_signal_noise.npy\")\n",
    "\n",
    "#clear_amplitude_conditions = [\"S\", \"M\", \"L\"]  #[\"S\", \"S/M\", \"M\", \"M/L\", \"L\"] #[\"S\", \"M\", \"L\"]\n",
    "ambig_amplitude_conditions = [\"S\", \"S/M\", \"M\", \"M/L\", \"L\"]\n",
    "\n",
    "#clear_time_constant_conditions = [\"equal_sharp\", \"equal_wide\", \"wide_sharp_negative_skew\", \"sharp_wide_positive_skew\"]\n",
    "ambig_time_constant_conditions = [\"equal_sharp\", \"equal_medium\", \"equal_wide\", \"wide_sharp_negative_skew\", \"wide_medium_negative_skew\",\"medium_sharp_negative_skew\",\"sharp_wide_positive_skew\", \"medium_wide_positive_skew\" ,\"sharp_medium_positive_skew\"]\n",
    "\n",
    "#[\"equal_sharp\", \"equal_medium\", \"equal_wide\", \"wide_sharp_negative_skew\", \"wide_medium_negative_skew\",\"medium_sharp_negative_skew\",\"sharp_wide_positive_skew\", \"medium_wide_positive_skew\" ,\"sharp_medium_positive_skew\"]\n",
    "#[\"equal_sharp\", \"equal_wide\", \"wide_sharp_negative_skew\", \"sharp_wide_positive_skew\"]\n",
    "\n",
    "ambiguous_conditions = [\"S/M\", \"M/L\", \"equal_medium\", \"wide_medium_negative_skew\", \"medium_sharp_negative_skew\", \"medium_wide_positive_skew\", \"sharp_medium_positive_skew\"]\n",
    "\n",
    "samples_per_condition = 1000\n",
    "samples_per_ambiguous_condition = 400\n",
    "\n",
    "ambig_cluster_dict = get_index_per_class(ambig_amplitude_conditions,ambig_time_constant_conditions, ambiguous_conditions, samples_per_condition, samples_per_ambiguous_condition)\n",
    "#clear_cluster_dict = get_index_per_class(clear_amplitude_conditions,clear_time_constant_conditions, [], samples_per_condition, samples_per_ambiguous_condition)\n",
    "\n",
    "\n",
    "#clear_true_labels = get_labels(clear_data, clear_cluster_dict)\n",
    "ambig_true_labels = get_labels(ambig_data, ambig_cluster_dict)\n",
    "\n",
    "#clear_clusters_ordered = list(range(0,len(clear_cluster_dict)+1))\n",
    "#clear_layout_label_mapping = labels_to_layout_mapping(clear_clusters_ordered, 4, (1,4)) #labels_to_layout_mapping(clusters_ordered, 4, (1,4)) #labels_to_layout_mapping(clusters_ordered, 9, (2,5))\n",
    "\n",
    "ambig_clusters_ordered = list(range(0,len(ambig_cluster_dict)+1))\n",
    "ambig_layout_label_mapping = labels_to_layout_mapping(ambig_clusters_ordered, 9, (2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(data,alpha,beta,gamma):\n",
    "    counter1 = np.outer(np.mean(data, axis = 1),np.mean(data, axis = 1))\n",
    "    counter2 = np.outer(np.std(data, axis = 1),np.std(data, axis = 1))\n",
    "    counter3 = np.cov(data,rowvar=True)\n",
    "\n",
    "    diag1 = counter1.diagonal()\n",
    "    diag2 = counter2.diagonal()\n",
    "    denom1 = diag1.reshape((len(diag1),1)) + diag1\n",
    "    denom2 = diag2.reshape((len(diag2),1)) + diag2\n",
    "\n",
    "    sim_matrix1 = 2 * counter1 / denom1\n",
    "    sim_matrix2 = 2 * counter2 / denom2\n",
    "    sim_matrix3 = (np.round(counter3/counter2,3)+1)/2\n",
    "\n",
    "    sim_matrix_mu_var = sim_matrix1**alpha * sim_matrix2**beta * sim_matrix3**gamma\n",
    "    \n",
    "    return sim_matrix_mu_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM_RAW(data):\n",
    "    # RAW SSIM (Dice Similarity)\n",
    "    #2xy/(x^2+y^2)\n",
    "    sim_matrix = data @ data.T \n",
    "    diag = sim_matrix.diagonal()\n",
    "    denom = diag.reshape((len(diag),1)) + diag\n",
    "    sim_matrix = 2 * sim_matrix / denom\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ambig_data\n",
    "true_labels = ambig_true_labels\n",
    "layout = ambig_layout_label_mapping\n",
    "reg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering SSIM_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_raw_matrix = SSIM_RAW(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_matrix = ssim_raw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [3,5,7,10,50,100,len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use precomputed matrix for constructing KNN-Graph\n",
      "Build symmetric KNN-Graph based on Similarity of data points!\n",
      "Weighting: True\n",
      "Calculate Normalized Laplacians\n",
      "Normalization: symmetric\n",
      "Calculate Eigenvalues and Vectors of Laplacian\n"
     ]
    }
   ],
   "source": [
    "for k in ks:\n",
    "    labels, eigvec, eigval = spectral_clustering(data, \"precomputed\", \"similarity\", range(1,50), k=k, precomputed_matrix=precomputed_matrix, mutual = False, weighting = True, normalize = True, reg_lambda = None, save_laplacian = False, save_eigenvalues_and_vectors = False)\n",
    "    if k == len(data):\n",
    "        k = \"Full\"\n",
    "    np.save(\"labels_ambig_equal_noise=[0,0.2]_SSIM_RAW_k=%s_reg=None_weighting=True\" % str(k),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_matrix_1_1_01 = SSIM(data,1,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_matrix_1_1_1 = SSIM(data,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [3,5,7,10,50,100,len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_matrix = ssim_matrix_1_1_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks:\n",
    "    labels, eigvec, eigval = spectral_clustering(data, \"precomputed\", \"similarity\", range(1,50), k=k, precomputed_matrix=precomputed_matrix, mutual = False, weighting = True, normalize = True, reg_lambda = None, save_laplacian = False, save_eigenvalues_and_vectors = False)\n",
    "    if k == len(data):\n",
    "        k = \"Full\"\n",
    "    np.save(\"labels_ambig_equal_noise=[0,0.2]_SSIM_1101_k=%s_reg=None_weighting=True\" % str(k),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_matrix = ssim_matrix_1_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks:\n",
    "    labels, eigvec, eigval = spectral_clustering(data, \"precomputed\", \"similarity\", range(1,50), k=k, precomputed_matrix=precomputed_matrix, mutual = False, weighting = True, normalize = True, reg_lambda = None, save_laplacian = False, save_eigenvalues_and_vectors = False)\n",
    "    if k == len(data):\n",
    "        k = \"Full\"\n",
    "    np.save(\"labels_ambig_equal_noise=[0,0.2]_SSIM_111_k=%s_reg=None_weighting=True\" % str(k),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral_clustering import calculate_dist_matrix\n",
    "dist_matrix_euclidean, _ = calculate_dist_matrix(data, \"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [3,5,7,10,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_matrix = dist_matrix_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use precomputed matrix for constructing KNN-Graph\n",
      "Build symmetric KNN-Graph based on Distance of data points!\n",
      "Weighting: False\n",
      "Calculate Normalized Laplacians\n",
      "Normalization: symmetric\n",
      "Calculate Eigenvalues and Vectors of Laplacian\n"
     ]
    }
   ],
   "source": [
    "for k in ks:\n",
    "    labels, eigvec, eigval = spectral_clustering(data, \"precomputed\", \"distance\", range(1,50), k=k, precomputed_matrix=precomputed_matrix, mutual = False, weighting = False, normalize = True, reg_lambda = None, save_laplacian = False, save_eigenvalues_and_vectors = False)\n",
    "    if k == len(data):\n",
    "        k = \"Full\"\n",
    "    np.save(\"labels_ambig_equal_noise=[0,0.2]_Euclidean_k=%s_reg=None_weighting=False\" % str(k),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ambig_data\n",
    "true_labels = ambig_true_labels\n",
    "\n",
    "save_file = \"F1_k=10_ambig_SSIM_RAW_clear_clusters\"#\"F1_k=Full_clear_Noise=[0,1]_SSIM_RAW\" \n",
    "save_file_clear_clusters = \"F1_k=10_ambig_SSIM_RAW_clear_clusters\" \n",
    "calculate_F1_for_clear_clusters_in_ambig_data = True\n",
    "#save_file_clear_clusters = \"F1_clear_clusters_k=%d_reg=%s_ambig_balanced_true_SSIM_EUCLIDEAN\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clear_data\n",
    "true_labels = clear_true_labels\n",
    "\n",
    "save_file = \"F1_k=10_clear_Noise=[0,1]_SSIM_Raw_weighting=True\" \n",
    "#save_file_clear_clusters = \"F1_k=Full_ambig_SSIM_clear_clusters\" \n",
    "calculate_F1_for_clear_clusters_in_ambig_data = False\n",
    "#save_file_clear_clusters = \"F1_clear_clusters_k=%d_reg=%s_ambig_balanced_true_SSIM_EUCLIDEAN\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate F1 score based on true training centroids!\n"
     ]
    }
   ],
   "source": [
    "clustered_labels = np.load(\"label_noise=[0,1]_SSIM_RAW_k=10_reg=None_weighted=True.npy\")\n",
    "\n",
    "clustered_labels_dict = {}\n",
    "    \n",
    "for i, labels in enumerate(clustered_labels):\n",
    "    clustered_labels_dict[i+1] = labels\n",
    "       \n",
    "        \n",
    "F1_score_per_k = get_F1_score_per_k(data, range(len(data)), range(len(data)), None, clustered_labels_dict, combination_type = \"true\" ,true_train_labels = true_labels)    \n",
    "\n",
    "np.save(save_file, F1_score_per_k) \n",
    "    \n",
    "if calculate_F1_for_clear_clusters_in_ambig_data:\n",
    "    clusters_from_ambig_dataset, counts = np.unique(true_labels, return_counts = True)\n",
    "    clear_clusters_from_ambig = clusters_from_ambig_dataset[np.where(counts == 1000)]\n",
    "    \n",
    "    clear_clusters_from_ambig_idx = np.where(np.isin(true_labels,clear_clusters_from_ambig) == True)[0]\n",
    "\n",
    "    clear_inidices = np.asarray(range(len(data)))[clear_clusters_from_ambig_idx]\n",
    "    \n",
    "\n",
    "    clear_clustered_labels_dict = {}\n",
    "    for i, labels in enumerate(clustered_labels):\n",
    "        clear_clustered_labels_dict[i+1] = labels[clear_clusters_from_ambig_idx]\n",
    "\n",
    "    clear_true_labels = true_labels[clear_clusters_from_ambig_idx]    \n",
    "\n",
    "    F1_score_per_k_clear_clusters = get_F1_score_per_k(data, clear_inidices, clear_inidices, None, clear_clustered_labels_dict, combination_type = \"true\" ,true_train_labels = clear_true_labels)\n",
    "\n",
    "    np.save(save_file_clear_clusters,F1_score_per_k_clear_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.1539520974236562,\n",
       " 2: 0.2793395475806112,\n",
       " 3: 0.34800058485997576,\n",
       " 4: 0.4062630010387748,\n",
       " 5: 0.49845682803827784,\n",
       " 6: 0.5870787336271097,\n",
       " 7: 0.6005523475951335,\n",
       " 8: 0.7057481739600017,\n",
       " 9: 0.7503794305927199,\n",
       " 10: 0.7741173118293209,\n",
       " 11: 0.7718687998517706,\n",
       " 12: 0.8141573719715776,\n",
       " 13: 0.7777232131611541,\n",
       " 14: 0.7672674929245016,\n",
       " 15: 0.7661165138017607,\n",
       " 16: 0.7405745348094017,\n",
       " 17: 0.7609373026212791,\n",
       " 18: 0.7349683519864573,\n",
       " 19: 0.7032886652871626,\n",
       " 20: 0.6619521776807519,\n",
       " 21: 0.647291580965391,\n",
       " 22: 0.5851346842635546,\n",
       " 23: 0.5865151628794486,\n",
       " 24: 0.5848442073021184,\n",
       " 25: 0.5648700467030915,\n",
       " 26: 0.5368231846558567,\n",
       " 27: 0.5391132551217305,\n",
       " 28: 0.5362109764517032,\n",
       " 29: 0.5201907184964494,\n",
       " 30: 0.506401469473674,\n",
       " 31: 0.4986165833434918,\n",
       " 32: 0.48690712211689735,\n",
       " 33: 0.4605545272032836,\n",
       " 34: 0.46980670950809095,\n",
       " 35: 0.4561349081264966,\n",
       " 36: 0.43122673937772826,\n",
       " 37: 0.4350657506814467,\n",
       " 38: 0.42293790272600146,\n",
       " 39: 0.42468187909668975,\n",
       " 40: 0.4026516521941282,\n",
       " 41: 0.39446667384292616,\n",
       " 42: 0.3885637854053096,\n",
       " 43: 0.38242333495669883,\n",
       " 44: 0.3805598693394426,\n",
       " 45: 0.37315575766914866,\n",
       " 46: 0.3628550109151317,\n",
       " 47: 0.35773704859915584,\n",
       " 48: 0.35116789450823177,\n",
       " 49: 0.33278348323990187}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score_per_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.15402960652515688,\n",
       " 2: 0.25908921476939833,\n",
       " 3: 0.3505291025909605,\n",
       " 4: 0.39726436740921234,\n",
       " 5: 0.45834110919806464,\n",
       " 6: 0.47645313342532875,\n",
       " 7: 0.4757990434079785,\n",
       " 8: 0.6632345401611653,\n",
       " 9: 0.6630907565173416,\n",
       " 10: 0.7010324122618977,\n",
       " 11: 0.7944956057331485,\n",
       " 12: 0.794200273105369,\n",
       " 13: 0.7941217642307014,\n",
       " 14: 0.8518802827668048,\n",
       " 15: 0.8514694712257833,\n",
       " 16: 0.9187238910797932,\n",
       " 17: 0.9187175748870922,\n",
       " 18: 0.9120526939579391,\n",
       " 19: 0.9118801077921017,\n",
       " 20: 0.8980971374956452,\n",
       " 21: 0.8952377796537089,\n",
       " 22: 0.87395071016424,\n",
       " 23: 0.8710560545121807,\n",
       " 24: 0.8673593966150471,\n",
       " 25: 0.8645145761393829,\n",
       " 26: 0.8679720892397811,\n",
       " 27: 0.8699686119868788,\n",
       " 28: 0.8661758248491223,\n",
       " 29: 0.8662564512955203,\n",
       " 30: 0.8651004246300973,\n",
       " 31: 0.8648204556995084,\n",
       " 32: 0.8148657577490128,\n",
       " 33: 0.8131567672231682,\n",
       " 34: 0.8142136193986921,\n",
       " 35: 0.7864742191345094,\n",
       " 36: 0.7571249182991883,\n",
       " 37: 0.785257020452987,\n",
       " 38: 0.7847372035095789,\n",
       " 39: 0.7536084669510672,\n",
       " 40: 0.7533574562502139,\n",
       " 41: 0.7817949680073618,\n",
       " 42: 0.7527435041728556,\n",
       " 43: 0.7522401557325183,\n",
       " 44: 0.7525412901111778,\n",
       " 45: 0.7215210508023325,\n",
       " 46: 0.7193093454254356,\n",
       " 47: 0.7187907914207812,\n",
       " 48: 0.7122829435532079,\n",
       " 49: 0.6820648518971796}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score_per_k_clear_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F1 for different Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"F1_k=Full_ambig_SSIM_clear_clusters.npy\",\"F1_k=10_ambig_SSIM_clear_clusters.npy\",\"F1_k=10_ambig_Euclidean_clear_clusters.npy\",\"F1_k=Full_ambig_SSIM_RAW_clear_clusters.npy \",\"F1_k=10_ambig_SSIM_RAW_clear_clusters.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores_clear_clusters = {}\n",
    "for file in files: \n",
    "    f1_dict = np.load(file,allow_pickle=True).item()\n",
    "    k_clusters = list(f1_dict.keys())\n",
    "    F1_scores = []\n",
    "    for i in k_clusters:\n",
    "        #mean_prediction_strengths.append(np.mean(prediction_strengths_per_k[k]))\n",
    "        #err_prediction_strengths.append(np.std(prediction_strengths_per_k[k]))\n",
    "        #min_prediction_strengths.append(np.amin(prediction_strengths_per_k[k]))\n",
    "        F1_scores.append(f1_dict[i])\n",
    "    F1_scores_clear_clusters_reg[reg] = F1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(20,10)\n",
    "plot_adjustments = [0.05,0.08,0.95, 0.91]\n",
    "save_file = \"Ambig_F1_clear_clusters_regularization_comparison_None_to_100_k=10_SSIM_EUCLIDEAN.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "k_clusters = range(1,50)\n",
    "for i,reg in enumerate(regs):\n",
    "    F1_scores = F1_scores_clear_clusters_reg[reg]\n",
    "    ax.plot(k_clusters, F1_scores, \"o-\", label=\"reg=%s\" % str(reg),color = \"C0%d\" % i,linewidth=3)\n",
    "\n",
    "    argmax_f1 = np.argmax(F1_scores[1:]) + 1\n",
    "\n",
    "    ax.annotate(\"#%d|Score=%.3f\" % (argmax_f1+1, F1_scores[argmax_f1]), (k_clusters[argmax_f1] - 1, F1_scores[argmax_f1] + 0.03 - i*0.03), fontsize=16, color = \"C0%d\" % i)\n",
    "\n",
    "\n",
    "title = \"F1-Score of Clear Clusters for Clustering with k Clusters \\n\" + configuration \n",
    "\n",
    "ax.set_title(title, fontsize=22, pad=20)\n",
    "ax.set_xticks(k_clusters)\n",
    "ax.set_xlabel(\"# Number of clusters\", fontsize=18, labelpad=10)\n",
    "ax.set_ylabel(\"F1-Score\", fontsize=18, labelpad=10),\n",
    "ax.set_ylim((0, 1.1))\n",
    "ax.tick_params(axis='y',labelsize=14)\n",
    "ax.tick_params(axis='x',labelsize=14)\n",
    "\n",
    "ax.set_yticks(np.arange(0, 1.1,0.1))\n",
    "left = plot_adjustments[0]\n",
    "bottom = plot_adjustments[1]\n",
    "right = plot_adjustments[2]\n",
    "top = plot_adjustments[3]\n",
    "\n",
    "plt.subplots_adjust(left,bottom,right, top)\n",
    "\n",
    "ax.legend(fontsize = 14, loc=\"lower right\")\n",
    "\n",
    "plt.savefig(save_file)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
